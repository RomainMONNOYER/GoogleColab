{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Input_TP5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK6fZUXolwPs"
      },
      "source": [
        "# **1. Informations matériel (GPU)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UEjh8Rulquq",
        "outputId": "b60ef868-477e-47d0-c203-1314bc240fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 25 20:10:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtS3fRhb5x6"
      },
      "source": [
        "# **2. Importation des librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS3XuLGyb5x_",
        "outputId": "aebef116-6034-4c00-e3dc-fb3eda2b94f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2 \n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n",
            "Keras version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6HqNeyYKraU"
      },
      "source": [
        "#**3. Téléchargement des données (radiographies Covid-19)\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdwkyRtmnN-",
        "outputId": "248c3c33-c1d8-404c-a287-6e3376ebaf6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf sample_data\n",
        "! wget https://smartappli.eu/Train_Test_Covid19.zip\n",
        "! unzip Train_Test_Covid19.zip\n",
        "! rm Train_Test_Covid19.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 20:10:03--  https://smartappli.eu/Train_Test_Covid19.zip\n",
            "Resolving smartappli.eu (smartappli.eu)... 51.254.94.183, 2001:41d0:301:12::20\n",
            "Connecting to smartappli.eu (smartappli.eu)|51.254.94.183|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:04--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:04--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:04--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:04--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:05--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:06--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:07--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:07--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "--2022-01-25 20:10:07--  https://smartappli.eu/\n",
            "Reusing existing connection to smartappli.eu:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://smartappli.eu [following]\n",
            "20 redirections exceeded.\n",
            "unzip:  cannot find or open Train_Test_Covid19.zip, Train_Test_Covid19.zip.zip or Train_Test_Covid19.zip.ZIP.\n",
            "rm: cannot remove 'Train_Test_Covid19.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-BpaZnLDmn"
      },
      "source": [
        "#**4. Création du fichier de labels \"classes.txt\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70eR5xy2nNZP"
      },
      "source": [
        "!printf '%s\\n' 'covid-19' 'normal' 'viral-pneumonia'> classes.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXXoZphLN1-"
      },
      "source": [
        "#**5. Paramètres d'entrainement et sélection du modèle pré-entrainé**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKf5hQLnUPi"
      },
      "source": [
        "nb_classes = 3\n",
        "image_size=(224,224)\n",
        "nbr_batch_size=8 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "dataset_name='New_DataSet_Covid19' #@param [\"New_DataSet_Covid19\",\"Dataset1\",\"Dataset2\",\"Dataset3\"]\n",
        "dataset_path = os.path.join(dataset_name,'train/')\n",
        "dataset_test_path = os.path.join(dataset_name,'test/')\n",
        "classes_path = \"classes.txt\"\n",
        "epochs = 100 #@param {type:\"slider\", min:5, max:100, step:5}\n",
        "classifier = \"Xception\" #@param [\"Xception\",\"VGG16\",\"VGG19\",\"ResNet50\",\"ResNet121\",\"ResNet152\",\"ResNet50V2\",\"ResNet121V2\",\"ResNet152V2\",\"InceptionV3\",\"InceptionResNetV2\",\"MobileNet\",\"MobileNetV2\",\"DenseNet121\",\"DenseNet169\",\"DenseNet201\",\"NASNetLarge\",\"NASNetMobile\"] {type:\"string\"}\n",
        "result_path = 'results/'+classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCDoxF6Xb5yN"
      },
      "source": [
        "# **6. Fonction de génération des données à partir de chemins**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzwI7D2Tb5yX"
      },
      "source": [
        "def generate_from_paths_and_labels(input_paths, labels, batch_size, input_size=image_size):\n",
        "    num_samples = len(input_paths)\n",
        "    while 1:\n",
        "        perm = np.random.permutation(num_samples)\n",
        "        input_paths = input_paths[perm]\n",
        "        labels = labels[perm]\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            inputs = list(map(\n",
        "                lambda x: image.load_img(x, target_size=input_size),\n",
        "                input_paths[i:i+batch_size]\n",
        "            ))\n",
        "            inputs = np.array(list(map(\n",
        "                lambda x: image.img_to_array(x),\n",
        "                inputs\n",
        "            )))\n",
        "            inputs = preprocess_input(inputs)\n",
        "            yield (inputs, labels[i:i+batch_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBzh646b5yz"
      },
      "source": [
        "# **7. Récupérer les images et leurs labels  (peut prendre quelques minutes)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy7xWs8kWqcW"
      },
      "source": [
        "def load_data(dataset_path, classes_path):\n",
        "  with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "  num_classes = len(classes)\n",
        "\n",
        "  # Récupurer les images et les classes\n",
        "  input_paths, labels = [], []\n",
        "  for class_name in os.listdir(dataset_path):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    class_id = classes.index(class_name)\n",
        "    for path in os.listdir(class_path):\n",
        "        path = os.path.join(class_path, path)\n",
        "        if imghdr.what(path) == None:\n",
        "            # this is not an image file\n",
        "            continue\n",
        "        input_paths.append(path)\n",
        "        labels.append(class_id)\n",
        "  return input_paths, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ55HVhkb5y3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "1fec44ae-752e-46f1-dbb4-2e3f692db0d0"
      },
      "source": [
        "input_paths, labels = load_data(dataset_path, classes_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ccd50ba03107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-d03842d3e578>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dataset_path, classes_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Récupurer les images et les classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0minput_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'New_DataSet_Covid19/train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTyWV0pQb5zD"
      },
      "source": [
        "# **8. Conversion des labels au format \"One Hot\" (A COMPLETER)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoWLjGra8Ls9"
      },
      "source": [
        "nb_classes = 3\n",
        "labels = np_utils.to_categorical(labels, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2AfPd88PC-"
      },
      "source": [
        "#**9. Conversion des données d'entrée au formar np.array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bc3CFC88WaR"
      },
      "source": [
        "input_paths = np.array(input_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl3NUiLJ8XXa"
      },
      "source": [
        "#**10. Permutation des données (A COMPLETER)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovlLxv8i8fYG"
      },
      "source": [
        "# shuffle dataset (permuter les données)\n",
        "perm = np.random.permutation(len(input_paths))\n",
        "labels = labels[perm]\n",
        "input_paths = input_paths[perm]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak4BTbvP8jAU"
      },
      "source": [
        "#**11. Division des données : 80% train et 20% validation (A COMPLETER)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKp1l4jAb5zG"
      },
      "source": [
        "# split dataset for training and validation\n",
        "border = 0.2                             \n",
        "# train_labels, val_labels = #???????????????????????????????????????????????????\n",
        "train_input_paths, val_input_paths, train_labels, val_labels = train_test_split(input_paths, labels, test_size = border, random_state=42)\n",
        "print(\"Training on %d images and labels\" % (len(train_input_paths)))\n",
        "print(\"Validation on %d images and labels\" % (len(val_input_paths)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxIm1jIrUknM"
      },
      "source": [
        "# **12. Modèle from Scractch  (A compléter)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicdDutmUz3D"
      },
      "source": [
        "nb_filters = 32\n",
        "kernel_size = (3,3)\n",
        "input_shape = (224,224,3)\n",
        "pool_size = (2,2)\n",
        "\n",
        "model = Sequential()\n",
        "# Layer 1\n",
        "model.add(Conv2D(nb_filters, kernel_size, input_shape= input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "# Layer 2\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "model.add(Conv2D(nb_filters, kernel_size, input_shape= input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "# Layer3\n",
        "model.add(MaxPooling2D(pool_size=pool_size))\n",
        "model.add(Flatten())\n",
        "# Layer 4\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(nb_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi8oBrIJWa5s"
      },
      "source": [
        "# **13. Téléchargement d'un modèle préentraîné et Transfer Learning (A compléter)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WCBo9Oyb5zc"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(include_top = False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "# create a custom top classifier\n",
        "x=base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x=Dense(1028, activation ='relu')(x)\n",
        "predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.inputs, outputs = predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6CWnXEPb5zX"
      },
      "source": [
        "# **14. Entraînement du modèle (A compléter)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbAlAYpm9fg5"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "stopper = EarlyStopping(monitor='val_loss',\n",
        "                        min_delta=0.1,\n",
        "                        patience=3,\n",
        "                        verbose=1,\n",
        "                        mode='auto')\n",
        "ckpt_save = os.path.join(\"./results/classifier\", 'model_fine_ep{epoch}_valloss{val_loss:.3f}.h5')\n",
        "checkpoint=ModelCheckpoint(ckpt_save, monitor=\"val_loss\", verbose=1, save_best_only=True, mode='auto')\n",
        "callback_list=[checkpoint, stopper]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPGAZ2Vab5zo"
      },
      "source": [
        "# pour permettre le ré-entrainement des couches\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# recompiler le modèle\n",
        "tf.keras.backend.clear_session()   # Supprimer les poids du dernier entrainement\n",
        "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy']) # Remplacer les *** par une optimiseur \n",
        "\n",
        "# Création du dossier pour sauvegrader le model\n",
        "if os.path.exists(result_path) == False:\n",
        "    os.makedirs(result_path)\n",
        "\n",
        "history=model.fit_generator(\n",
        "    generator=generate_from_paths_and_labels(\n",
        "        input_paths=train_input_paths,\n",
        "        labels=train_labels,\n",
        "        batch_size=nbr_batch_size,\n",
        "        input_size=input_shape # Adapter suivant le modèle\n",
        "        \n",
        "    ),\n",
        "    steps_per_epoch=math.ceil(len(train_input_paths) / nbr_batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=generate_from_paths_and_labels(\n",
        "        input_paths=train_input_paths,\n",
        "        labels=train_labels,\n",
        "        batch_size=nbr_batch_size,\n",
        "        input_size=input_shape\n",
        "    ),\n",
        "    validation_steps=math.ceil(len(val_input_paths) / nbr_batch_size),\n",
        "    callbacks=callback_list,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVOg-VgI9YMB"
      },
      "source": [
        "#**15. Sauvegarder me modèle final (A COMPLETER)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmJ003EcJZG8"
      },
      "source": [
        "model.save(\"./results/test.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_ljTXlMSIZ"
      },
      "source": [
        "#**16. Affichage des courbes d'entrainement/validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIwdjee_KLk"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqwe00csYS8Y"
      },
      "source": [
        "# **17. Récupérer les données de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuOc5xkTYPqb"
      },
      "source": [
        "test_paths, test_labels = load_data(dataset_test_path, classes_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Nyn3FfmTFM"
      },
      "source": [
        "# **18. Préparer les données de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkQVC08ZYkdn"
      },
      "source": [
        "test_labels=to_categorical(test_labels,nb_classes)\n",
        "test_paths = np.array(test_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy7SWtUGmpnt"
      },
      "source": [
        "# **19. Calculer le score de test (A compléter)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzOzgFj2ZdHB"
      },
      "source": [
        "score = model.evaluate_generator(\n",
        "    generate_from_paths_and_labels(\n",
        "      input_paths= val_input_paths,\n",
        "      labels=val_labels,\n",
        "      batch_size=128,\n",
        "      input_size=input_shape),\n",
        "    steps=(len(test_paths)/128),workers = 1)\n",
        "\n",
        "print (\"Test images number:\", len(test_paths))\n",
        "\n",
        "print(\"Test %s: %.2f%%\" % (model.metrics_names[0], score[0]))\n",
        "print(\"Test %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}